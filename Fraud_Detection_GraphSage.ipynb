{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya26189/fraud-detection/blob/main/Fraud_Detection_GraphSage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Xd3D3xL2zC",
        "outputId": "c00cc9b3-be94-46c8-ee94-0c0e0723cf03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Setup & imports\n",
        "# -------------------------\n",
        "# Install required dependencies\n",
        "\n",
        "%pip install torch-geometric -q\n",
        "%pip install torch -q\n",
        "print('Dependencies installed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF0lvnSu8UsW",
        "outputId": "8dc217bb-fc88-4f96-ee36-1fe7051b24b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Storage\n",
        "# -------------------------\n",
        "# Mount Google Drive for persistent file storageTemperatureScaler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive mounted')\n",
        "\n",
        "base_path = '/content/drive/MyDrive/GNN'\n",
        "# Update base_path to save to Google Drive instead of local Windows path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oE_jEcg5MO3k"
      },
      "outputs": [],
      "source": [
        "class TemperatureScaler:\n",
        "# FEATURE ENGINEERING: 3 Quick Wins for Accuracy\n",
        "  from sklearn.preprocessing import RobustScaler\n",
        "  from torch_geometric.utils import degree as compute_degree\n",
        "  import torch\n",
        "\n",
        "  def apply_feature_engineering(data):\n",
        "      \"\"\"Apply RobustScaler + Degree features\"\"\"\n",
        "      # 1. RobustScaler for features (handles outliers better)\n",
        "      X = data.x.cpu().numpy()\n",
        "      scaler = RobustScaler()\n",
        "      X_scaled = scaler.fit_transform(X)\n",
        "      data.x = torch.from_numpy(X_scaled).float()\n",
        "\n",
        "      # 2. Add degree features (captures graph centrality)\n",
        "      row, col = data.edge_index\n",
        "      deg = compute_degree(row, num_nodes=data.num_nodes).float()\n",
        "      indeg = compute_degree(col, num_nodes=data.num_nodes).float()\n",
        "      deg_norm = (deg - deg.mean()) / (deg.std() + 1e-9)\n",
        "      indeg_norm = (indeg - indeg.mean()) / (indeg.std() + 1e-9)\n",
        "      data.x = torch.cat([data.x, deg_norm.view(-1,1), indeg_norm.view(-1,1)], dim=1)\n",
        "\n",
        "      print(f\"Features after engineering: {data.x.shape}\")\n",
        "      return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gr7goDdl5915"
      },
      "outputs": [],
      "source": [
        "# FEATURE ENGINEERING: 3 Quick Wins for Accuracy\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from torch_geometric.utils import degree as compute_degree\n",
        "import torch\n",
        "\n",
        "def apply_feature_engineering(data):\n",
        "    \"\"\"Apply RobustScaler + Degree features\"\"\"\n",
        "    # 1. RobustScaler for features (handles outliers better)\n",
        "    X = data.x.cpu().numpy()\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    data.x = torch.from_numpy(X_scaled).float()\n",
        "\n",
        "    # 2. Add degree features (captures graph centrality)\n",
        "    row, col = data.edge_index\n",
        "    deg = compute_degree(row, num_nodes=data.num_nodes).float()\n",
        "    indeg = compute_degree(col, num_nodes=data.num_nodes).float()\n",
        "    deg_norm = (deg - deg.mean()) / (deg.std() + 1e-9)\n",
        "    indeg_norm = (indeg - indeg.mean()) / (indeg.std() + 1e-9)\n",
        "    data.x = torch.cat([data.x, deg_norm.view(-1,1), indeg_norm.view(-1,1)], dim=1)\n",
        "\n",
        "    print(f\"Features after engineering: {data.x.shape}\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "wNkqAqhALeoW",
        "outputId": "ad5d3978-332c-43a8-97d8-067213598a81"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (ipython-input-1332726356.py, line 17)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1332726356.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    with torch.no_grad\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Core pipeline\n",
        "# -------------------------\n",
        "import os, random, torch, numpy as np, pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "from torch_geometric.datasets import EllipticBitcoinDataset\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from torch_geometric.utils import degree as compute_degree\n",
        "\n",
        "with torch.no_grad\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from torch_geometric.utils import degree as compute_degree\n",
        "import torch\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Feature engineering\n",
        "# -------------------------\n",
        "\n",
        "\n",
        "def apply_feature_engineering(data):\n",
        "    \"\"\"Apply RobustScaler to node features.\"\"\"\n",
        "    X = data.x.cpu().numpy()\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    data.x = torch.from_numpy(X_scaled).float()\n",
        "\n",
        "\n",
        "    print(f\"Features after engineering: {data.x.shape}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "base_path = '/content/drive/MyDrive/Aditya_Singh_GraphGE_Submission'\n",
        "os.makedirs(os.path.join(base_path, 'graphge/results/figures'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_path, 'graphge/data'), exist_ok=True)\n",
        "\n",
        "\n",
        "print(\"Loading Elliptic...\")\n",
        "ds = EllipticBitcoinDataset(root=os.path.join(base_path, 'graphge/data'))\n",
        "# Assumes data.y âˆˆ {0,1} for masked nodes\n",
        "data = ds[0]\n",
        "known = (data.y == 0) | (data.y == 1)\n",
        "data.train_mask = data.train_mask & known\n",
        "data.test_mask = data.test_mask & known\n",
        "\n",
        "\n",
        "if not hasattr(data, 'val_mask') or data.val_mask.sum() == 0:\n",
        "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
        "    perm = train_idx[torch.randperm(train_idx.numel(), generator=torch.Generator().manual_seed(SEED))]\n",
        "    val_ratio = 0.10 # Using same ratio as in load_data.py\n",
        "    val_size = max(1, int(val_ratio * perm.numel()))\n",
        "    val_idx = perm[:val_size]\n",
        "    new_train_idx = perm[val_size:]\n",
        "\n",
        "\n",
        "    data.val_mask = torch.zeros_like(data.train_mask)\n",
        "    data.val_mask[val_idx] = True\n",
        "    # val_mask is disjoint from train_mask\n",
        "    data.train_mask[:] = False\n",
        "    data.train_mask[new_train_idx] = True\n",
        "    print(f\"Created val_mask with {data.val_mask.sum()} samples (from original train_mask).\")\n",
        "\n",
        "\n",
        "val_mask_cpu = data.val_mask.clone()\n",
        "\n",
        "\n",
        "# Apply feature engineering and move to device\n",
        "# Mutates data.x in-place\n",
        "data = apply_feature_engineering(data)\n",
        "# Moves data and masks to the selected device\n",
        "data = data.to(device)\n",
        "data.val_mask = val_mask_cpu.to(device)\n",
        "print(\"Feature engineering applied\")\n",
        "y_tr = data.y[data.train_mask]\n",
        "n0, n1 = (y_tr == 0).sum().item(), (y_tr == 1).sum().item()\n",
        "class_w = torch.tensor([1.0, n0 / (n1 + 1e-8)]).to(device)\n",
        "print(f\"Train: {data.train_mask.sum()} | Test: {data.test_mask.sum()}\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Model\n",
        "# -------------------------\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, out_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, force_dropout=None):\n",
        "        use_dropout = self.training if force_dropout is None else force_dropout\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=use_dropout)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "model = GraphSAGE(data.x.shape[1], 64, 2, 0.5).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Training loop\n",
        "# -------------------------\n",
        "print(\"Training...\")\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    opt.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_w)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# Monte Carlo dropout inference\n",
        "# probs: (T, N, C)\n",
        "# entropy: (N,)\n",
        "def mc_dropout_predict(model, data, mask, T=30):\n",
        "    \"\"\"Returns mean probabilities and per-node entropy.\"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "    for _ in range(T):\n",
        "        with torch.no_grad():\n",
        "            logits = model(data.x, data.edge_index, force_dropout=True)\n",
        "            probs.append(torch.exp(logits[mask]).cpu().numpy())\n",
        "\n",
        "\n",
        "    probs = np.stack(probs, axis=0)  # shape: (T, N, 2)\n",
        "    mean_probs = probs.mean(axis=0)\n",
        "    entropy = -(mean_probs * np.log(mean_probs + 1e-12)).sum(axis=1)\n",
        "    return mean_probs, entropy\n",
        "\n",
        "\n",
        "print(\"\\nEvaluation...\")\n",
        "y_test = data.y[data.test_mask].cpu().numpy()\n",
        "probs_mc, entropy_mc = mc_dropout_predict(model, data, data.test_mask, T=30)\n",
        "yhat = probs_mc.argmax(axis=1)\n",
        "f1 = f1_score(y_test, yhat, zero_division=0)\n",
        "prauc = average_precision_score(y_test, probs_mc[:, 1])\n",
        "print(f\"F1={f1:.4f}, PR-AUC={prauc:.4f}\")\n",
        "\n",
        "\n",
        "# Writes metrics to graphge/results/metrics.csv\n",
        "metrics = pd.DataFrame([{'method': 'GraphSAGE', 'f1': f1, 'prauc': prauc, 'seed': 0}])\n",
        "metrics.to_csv(os.path.join(base_path, 'graphge/results/metrics.csv'), index=False)\n",
        "print(f\"Saved: {os.path.join(base_path, 'graphge/results/metrics.csv')}\")\n",
        "\n",
        "\n",
        "# y_prob: (N, C)\n",
        "# y_true: (N,)\n",
        "def plot_reliability(y_true, y_prob, save_path, n_bins=15):\n",
        "    conf = y_prob.max(axis=1)\n",
        "    pred = y_prob.argmax(axis=1)\n",
        "    correct = (pred == y_true).astype(float)\n",
        "\n",
        "\n",
        "    bins = np.linspace(0, 1, n_bins + 1)\n",
        "    bin_conf, bin_acc = [], []\n",
        "\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        lo, hi = bins[i], bins[i+1]\n",
        "        mask = (conf > lo) & (conf <= hi)\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        bin_conf.append(conf[mask].mean())\n",
        "        bin_acc.append(correct[mask].mean())\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Perfect')\n",
        "    plt.plot(bin_conf, bin_acc, '-o', linewidth=2)\n",
        "    plt.xlabel(\"Confidence\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Reliability Diagram\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=200, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "plot_reliability(y_test, probs_mc, os.path.join(base_path, 'graphge/results/figures/reliability.png'))\n",
        "print(f\"Saved: {os.path.join(base_path, 'graphge/results/figures/reliability.png')}\")\n",
        "\n",
        "\n",
        "# y_prob: (N, C)\n",
        "# entropy: (N,)\n",
        "def risk_coverage_curve(y_true, y_prob, entropy, n_points=60):\n",
        "    pred = y_prob.argmax(axis=1)\n",
        "    errors = (pred != y_true).astype(float)\n",
        "    thresholds = np.quantile(entropy, np.linspace(0, 1, n_points))\n",
        "    coverage, risk = [], []\n",
        "\n",
        "\n",
        "    for thr in thresholds:\n",
        "        keep = entropy <= thr\n",
        "        coverage.append(keep.mean())\n",
        "        risk.append(errors[keep].mean() if keep.sum() > 0 else 0.0)\n",
        "\n",
        "\n",
        "    return np.array(coverage), np.array(risk)\n",
        "\n",
        "\n",
        "cov, risk = risk_coverage_curve(y_test, probs_mc, entropy_mc, n_points=60)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(cov, risk, linewidth=2)\n",
        "plt.xlabel('Coverage')\n",
        "plt.ylabel('Risk')\n",
        "plt.title('Risk-Coverage Curve (MC Dropout Triage)')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, 'graphge/results/figures/risk_coverage.png'), dpi=200, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"Saved: {os.path.join(base_path, 'graphge/results/figures/risk_coverage.png')}\")\n",
        "\n",
        "\n",
        "print(\"MC dropout completed\")\n",
        "print(\"Entropy computed\")\n",
        "print(\"Wrong predictions entropy computed\")\n",
        "print(\"Risk-coverage computed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RMG64MRqNQN2"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QFG5faMBAqj9",
        "outputId": "c1f223ac-5fc3-4f14-ce3e-2986c03c699a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (ipython-input-3503023985.py, line 48)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3503023985.py\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    axes[1].hist(expected_entropy, bins=30, alpha=0.7, edgecolor='black', cofor _ in range(T):lor='blue')\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "# Decomposes uncertainty into model uncertainty (epistemic) and data noise (aleatoric)\n",
        "\n",
        "def mc_dropout_predict_full(model, data, mask, T=30):\n",
        "    \"\"\"Returns probs_T, mean_probs, total_entropy, expected_entropy, epistemic.\"\"\"\n",
        "    model.eval()\n",
        "    probs_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for _ in range(T):\n",
        "        logits = model(data.x, data.edge_index, force_dropout=True)\n",
        "        probs = torch.exp(logits[mask])\n",
        "        probs_list.append(probs.cpu().numpy())\n",
        "\n",
        "    probs_T = np.stack(probs_list, axis=0)  # (T, N, C)\n",
        "    mean_probs = probs_T.mean(axis=0)  # (N, C)\n",
        "\n",
        "    eps = 1e-12\n",
        "    total_entropy = -(mean_probs * np.log(mean_probs + eps)).sum(axis=1)\n",
        "    expected_entropy = -(probs_T * np.log(probs_T + eps)).sum(axis=2).mean(axis=0)\n",
        "    epistemic = total_entropy - expected_entropy  # mutual information\n",
        "\n",
        "    return probs_T, mean_probs, total_entropy, expected_entropy, epistemic\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Computing uncertainty decomposition\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model.eval()\n",
        "probs_T, probs_mc, total_entropy, expected_entropy, epistemic = mc_dropout_predict_full(\n",
        "    model, data, data.test_mask, T=30\n",
        ")\n",
        "\n",
        "y_test = data.y[data.test_mask].cpu().numpy()\n",
        "\n",
        "print(\"Uncertainty decomposition results:\")\n",
        "print(f\"  - Mean Epistemic (Model Uncertainty): {epistemic.mean():.4f}\")\n",
        "print(f\"  - Mean Aleatoric (Data Noise): {expected_entropy.mean():.4f}\")\n",
        "print(f\"  - Mean Total Entropy: {total_entropy.mean():.4f}\")\n",
        "print(f\"  - Ratio Epistemic/Aleatoric: {epistemic.mean() / (expected_entropy.mean() + 1e-8):.4f}\")\n",
        "\n",
        "# Plot distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "axes[0].hist(epistemic, bins=30, alpha=0.7, edgecolor='black', color='red')\n",
        "axes[0].set_title('Epistemic (Model Uncertainty)')\n",
        "axes[0].set_xlabel('Epistemic Uncertainty')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "axes[1].hist(expected_entropy, bins=30, alpha=0.7, edgecolor='black', cocolorfor _ in range(T):lor='blue')\n",
        "axes[1].set_title('Aleatoric (Data Noise)')\n",
        "axes[1].set_xlabel('Aleatoric Uncertainty')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "axes[2].scatter(epistemic, expected_entropy, alpha=0.3, s=10)\n",
        "axes[2].set_title('Epistemic vs Aleatoric')\n",
        "axes[2].set_xlabel('Epistemic')\n",
        "axes[2].set_ylabel('Aleatoric')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, 'graphge/results/figures/epistemic_aleatoric.png'), dpi=200, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(f\"Saved: {os.path.join(base_path, 'graphge/results/figures/epistemic_aleatoric.png')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6279loqHs4o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49iybzrhNQN5"
      },
      "outputs": [],
      "source": [
        "def mc_dropout_predict_fulld(model, data, mask, T=30):\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "  print(\"Running block\")\n",
        "  print(\"=\"*50)\n",
        "\n",
        "  # Class counts from training data\n",
        "  y_tr = data.y[data.train_mask]\n",
        "  n0 = (y_tr == 0).sum().item()\n",
        "  n1 = (y_tr == 1).sum().item()\n",
        "  class_counts = {'class_0': n0, 'class_1': n1}\n",
        "\n",
        "  # Final class weights\n",
        "  weight_0 = 1.0\n",
        "  weight_1 = n0 / (n1 +with torch 1e-8)\n",
        "  class_weights = {'class_0': weight_0, 'class_1': weight_1}\n",
        "\n",
        "  print(f\"Class Counts: {class_counts}\")\n",
        "  print(f\"Final Class Weights: {class_weights}\")\n",
        "\n",
        "  # Append to metrics.csv\n",
        "  import pandas as pd\n",
        "  metrics_file = os.path.join(base_path, 'graphge/results/metrics.csv')\n",
        "  if os.path.exists(metrics_file):\n",
        "      df = pd.read_csv(metrics_file)\n",
        "  else:\n",
        "      df = pd.DataFrame()\n",
        "\n",
        "  df['class_counts'] = str(class_counts)\n",
        "  df['class_weights'] = str(class_weights)\n",
        "  # Appends class counts and weights to metrics file\n",
        "  df.to_csv(metrics_file, index=False)\n",
        "  print(f\"Logged to {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5682glANQN5"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Has val_mask: {hasattr(data, 'val_mask')}\")\n",
        "if hasattr(data, 'val_mask'):\n",
        "    print(f\"val_mask sum: {data.val_mask.sum()}\")\n",
        "\n",
        "# val_mask selects validation nodes\n",
        "probs_val_mc, entropy_val_mc = mc_dropout_predict(model, data, data.val_mask, T=30)\n",
        "y_val = data.y[data.val_mask].cpu().numpy()\n",
        "\n",
        "# Sweep thresholds from 0.1 to 0.9\n",
        "thresholds = np.arange(0.1, 0.95, 0.05)\n",
        "f1_scores = []\n",
        "for thr in thresholds:\n",
        "    y_pred = (probs_val_mc[:, 1] > thr).astype(int)\n",
        "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "best_f1_val = f1_scores[best_idx]\n",
        "\n",
        "print(f\"Best threshold on validation: {best_threshold:.2f} with F1: {best_f1_val:.4f}\")\n",
        "\n",
        "# Apply to test set\n",
        "# F1 before (default threshold 0.5)\n",
        "y_pred_before = (probs_mc[:, 1] > 0.5).astype(int)\n",
        "f1_before = f1_score(y_test, y_pred_before, zero_division=0)\n",
        "\n",
        "# F1 after (best threshold)\n",
        "y_pred_after = (probs_mc[:, 1] > best_threshold).astype(int)\n",
        "f1_after = f1_score(y_test, y_pred_after, zero_division=0)\n",
        "\n",
        "print(f\"F1 before thresholding: {f1_before:.4f}\")\n",
        "print(f\"F1 after thresholding: {f1_after:.4f}\")\n",
        "\n",
        "# Append to metrics.csv\n",
        "df = pd.read_csv(metrics_file)\n",
        "df['best_threshold'] = best_threshold\n",
        "df['f1_before_threshold'] = f1_before\n",
        "df['f1_after_threshold'] = f1_after\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Logged to {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_E3OmzMNQN5"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Parameter variations\n",
        "# -------------------------\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def compute_entropy_auc(y_true, y_pred, entropy):\n",
        "    errors = (y_pred != y_true).astype(int)\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    return roc_auc_score(errors, -entropy)  # higher entropy -> higher error prob, so negative for AUC\n",
        "\n",
        "dropout_rates = [0.0, 0.2, 0.5, 0.7]\n",
        "results = []\n",
        "\n",
        "for dropout in dropout_rates:\n",
        "    print(f\"\\nTraining with dropout={dropout}\")\n",
        "\n",
        "    # Reset model\n",
        "    model_ab = GraphSAGE(data.x.shape[1], 64, 2, dropout).to(device)\n",
        "    opt_ab = torch.optim.Adam(model_ab.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(50):\n",
        "    model_ab.train()\n",
        "    opt_ab.zero_grad()\n",
        "    out = model_ab(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_w)\n",
        "    loss.backward()\n",
        "    opt_ab.step()\n",
        "\n",
        "    # Evaluate\n",
        "    probs_mc_ab, entropy_mc_ab = mc_dropout_predict(model_ab, data, data.test_mask, T=30)\n",
        "    y_pred_ab = probs_mc_ab.argmax(axis=1)\n",
        "    f1_ab = f1_score(y_test, y_pred_ab, zero_division=0)\n",
        "    ece_ab = compute_ece(y_test, probs_mc_ab)\n",
        "    entropy_auc_ab = compute_entropy_auc(y_test, y_pred_ab, entropy_mc_ab)\n",
        "\n",
        "    results.append({\n",
        "    'dropout': dropout,\n",
        "    'f1': f1_ab,\n",
        "    'ece': ece_ab,\n",
        "    'entropy_auc': entropy_auc_ab\n",
        "    })\n",
        "\n",
        "    print(f\"  F1: {f1_ab:.4f}, ECE: {ece_ab:.4f}, Entropy-AUC: {entropy_auc_ab:.4f}\")\n",
        "\n",
        "# Plot\n",
        "dropouts = [r['dropout'] for r in results]\n",
        "f1s = [r['f1'] for r in results]\n",
        "eces = [r['ece'] for r in results]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(dropouts, f1s, '-o')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('Dropout vs F1')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(dropouts, eces, '-o')\n",
        "plt.xlabel('Dropout Rate')\n",
        "plt.ylabel('ECE')\n",
        "plt.title('Dropout vs ECE')\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, 'graphge/results/figures/dropout_ablation.png'), dpi=200)\n",
        "plt.close()\n",
        "print(\"Saved: {os.path.join(base_path, 'graphge/results/figures/dropout_ablation.png')}\")\n",
        "\n",
        "# Append to metrics\n",
        "df = pd.read_csv(metrics_file)\n",
        "for r in results:\n",
        "    df[f\"f1_dropout_{r['dropout']}\"] = r['f1']\n",
        "    df[f\"ece_dropout_{r['dropout']}\"] = r['ece']\n",
        "\n",
        "    df[f\"entropy_auc_dropout_{r['dropout']}\"] = r['entropy_auc']\n",
        "    print(f\"Logged to {metrics_file}\")\n",
        "df.to_csv(metrics_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE9xC_l3NQN5"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Train with hidden_dim=128\n",
        "model_128 = GraphSAGE(data.x.shape[1], 128, 2, 0.5).to(device)\n",
        "opt_128 = torch.optim.Adam(model_128.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "print(\"Training with hidden_dim=128\")\n",
        "for epoch in range(50):\n",
        "    model_128.train()\n",
        "    opt_128.zero_grad()\n",
        "    out = model_128(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_w)\n",
        "    loss.backward()\n",
        "    opt_128.step()\n",
        "\n",
        "# Evaluate\n",
        "probs_mc_128, entropy_mc_128 = mc_dropout_predict(model_128, data, data.test_mask, T=30)\n",
        "y_pred_128 = probs_mc_128.argmax(axis=1)\n",
        "f1_128 = f1_score(y_test, y_pred_128, zero_division=0)\n",
        "ece_128 = compute_ece(y_test, probs_mc_128)\n",
        "entropy_auc_128 = compute_entropy_auc(y_test, y_pred_128, entropy_mc_128)\n",
        "\n",
        "print(f\"Baseline (hidden=64): F1={f1:.4f}, ECE={compute_ece(y_test, probs_mc):.4f}\")\n",
        "print(f\"Hidden=128: F1={f1_128:.4f}, ECE={ece_128:.4f}, Entropy-AUC={entropy_auc_128:.4f}\")\n",
        "\n",
        "# Append to metrics\n",
        "df = pd.read_csv(metrics_file)\n",
        "df['f1_hidden_128'] = f1_128\n",
        "df['ece_hidden_128'] = ece_128\n",
        "df['entropy_auc_hidden_128'] = entropy_auc_128\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Logged to {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7_31JXPNQN5"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTraining without degree features\")\n",
        "\n",
        "def apply_feature_engineering_ablation(data, include_degree=True):\n",
        "    \"\"\"Apply RobustScaler + optionally Degree features\"\"\"\n",
        "    # RobustScaler\n",
        "    X = data.x.cpu().numpy()\n",
        "    scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    data.x = torch.from_numpy(X_scaled).float()\n",
        "\n",
        "    if include_degree:\n",
        "    row, col = data.edge_index\n",
        "    deg = compute_degree(row, num_nodes=data.num_nodes).float()\n",
        "    indeg = compute_degree(col, num_nodes=data.num_nodes).float()\n",
        "    deg_norm = (deg - deg.mean()) / (deg.std() + 1e-9)\n",
        "    indeg_norm = (indeg - indeg.mean()) / (indeg.std() + 1e-9)\n",
        "    data.x = torch.cat([data.x, deg_norm.view(-1,1), indeg_norm.view(-1,1)], dim=1)\n",
        "\n",
        "    print(f\"Features after engineering: {data.x.shape}\")\n",
        "    return data\n",
        "\n",
        "# Experiment 1: Without degree\n",
        "data_no_deg = data.clone()\n",
        "data_no_deg = data_no_deg.cpu()\n",
        "data_no_deg = apply_feature_engineering_ablation(data_no_deg, include_degree=False)\n",
        "data_no_deg = data_no_deg.to(device)\n",
        "model_no_deg = GraphSAGE(data_no_deg.x.shape[1], 64, 2, 0.5).to(device)\n",
        "opt_no_deg = torch.optim.Adam(model_no_deg.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "for epoch in range(50):\n",
        "    model_no_deg.train()\n",
        "    opt_no_deg.zero_grad()\n",
        "    out = model_no_deg(data_no_deg.x, data_no_deg.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask], weight=class_w)\n",
        "    loss.backward()\n",
        "    opt_no_deg.step()\n",
        "\n",
        "probs_mc_no_deg, entropy_mc_no_deg = mc_dropout_predict(model_no_deg, data_no_deg, data.test_mask, T=30)\n",
        "y_pred_no_deg = probs_mc_no_deg.argmax(axis=1)\n",
        "f1_no_deg = f1_score(y_test, y_pred_no_deg, zero_division=0)\n",
        "ece_no_deg = compute_ece(y_test, probs_mc_no_deg)\n",
        "entropy_auc_no_deg = compute_entropy_auc(y_test, y_pred_no_deg, entropy_mc_no_deg)\n",
        "\n",
        "# Separation: mean entropy for correct vs wrong\n",
        "correct_no_deg = y_pred_no_deg == y_test\n",
        "wrong_no_deg = ~correct_no_deg\n",
        "sep_correct_no_deg = entropy_mc_no_deg[correct_no_deg].mean() if correct_no_deg.sum() > 0 else 0\n",
        "sep_wrong_no_deg = entropy_mc_no_deg[wrong_no_deg].mean() if wrong_no_deg.sum() > 0 else 0\n",
        "\n",
        "print(f\"Without degree: F1={f1_no_deg:.4f}, ECE={ece_no_deg:.4f}, Entropy-AUC={entropy_auc_no_deg:.4f}\")\n",
        "print(f\"Separation: Correct entropy={sep_correct_no_deg:.4f}, Wrong entropy={sep_wrong_no_deg:.4f}\")\n",
        "\n",
        "# Experiment 2: With degree (baseline)\n",
        "# Already have from original\n",
        "f1_with_deg = f1\n",
        "ece_with_deg = compute_ece(y_test, probs_mc)\n",
        "entropy_auc_with_deg = compute_entropy_auc(y_test, yhat, entropy_mc)\n",
        "\n",
        "correct_with_deg = yhat == y_test\n",
        "wrong_with_deg = ~correct_with_deg\n",
        "sep_correct_with_deg = entropy_mc[correct_with_deg].mean() if correct_with_deg.sum() > 0 else 0\n",
        "sep_wrong_with_deg = entropy_mc[wrong_with_deg].mean() if wrong_with_deg.sum() > 0 else 0\n",
        "\n",
        "print(f\"With degree: F1={f1_with_deg:.4f}, ECE={ece_with_deg:.4f}, Entropy-AUC={entropy_auc_with_deg:.4f}\")\n",
        "print(f\"Separation: Correct entropy={sep_correct_with_deg:.4f}, Wrong entropy={sep_wrong_with_deg:.4f}\")\n",
        "\n",
        "# Append to metrics\n",
        "df = pd.read_csv(metrics_file)\n",
        "df['f1_no_degree'] = f1_no_deg\n",
        "df['ece_no_degree'] = ece_no_deg\n",
        "df['entropy_auc_no_degree'] = entropy_auc_no_deg\n",
        "df['sep_correct_no_degree'] = sep_correct_no_deg\n",
        "df['sep_wrong_no_degree'] = sep_wrong_no_deg\n",
        "df['f1_with_degree'] = f1_with_deg\n",
        "df['ece_with_degree'] = ece_with_deg\n",
        "df['entropy_auc_with_degree'] = entropy_auc_with_deg\n",
        "df['sep_correct_with_degree'] = sep_correct_with_deg\n",
        "df['sep_wrong_with_degree'] = sep_wrong_with_deg\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Logged to {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me74IoTxNQN6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Already computed in previous steps, but log for baseline\n",
        "entropy_auc = compute_entropy_auc(y_test, yhat, entropy_mc)\n",
        "print(f\"Entropy-AUC: {entropy_auc:.4f}\")\n",
        "\n",
        "# Append\n",
        "df = pd.read_csv(metrics_file)\n",
        "df['entropy_auc_baseline'] = entropy_auc\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Logged to {metrics_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efDmZmlYNQN6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "readme_content = \"\"\"\n",
        "# Graph Neural Network for Fraud Detection with Uncertainty Quantification\n",
        "\n",
        "This project implements a GraphSAGE model with Monte Carlo Dropout.\n",
        "\n",
        "## Implementation\n",
        "\n",
        "- GraphSAGE (2 layers)\n",
        "- Monte Carlo Dropout (30 forward passes)\n",
        "- Weighted loss for class imbalance\n",
        "- Feature engineering: RobustScaler and degree features\n",
        "- Temperature scaling for calibration\n",
        "- Uncertainty decomposition and temporal analysis\n",
        "\n",
        "## Measurements\n",
        "\n",
        "- F1 score, precision, recall\n",
        "- Expected Calibration Error (ECE)\n",
        "- Entropy-AUC\n",
        "- Risk-coverage curves\n",
        "\n",
        "## Artifacts Produced\n",
        "\n",
        "- metrics_summary.csv\n",
        "- reliability.png\n",
        "- risk_coverage.png\n",
        "- epistemic_aleatoric.png\n",
        "- localized_uncertainty.png\n",
        "- README.md\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(base_path, 'README.md'), 'w') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrhTMQWNNQN6"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not hasattr(data, 'time') or data.time is None:\n",
        "    original_data_from_ds = ds[0]\n",
        "\n",
        "if hasattr(original_data_from_ds, 'time') and original_data_from_ds.time is not None:\n",
        "    test_time = original_data_from_ds.time[data.test_mask].cpu().numpy()\n",
        "elif hasattr(data, 'time_step'):\n",
        "    test_time = data.time_step[data.test_mask].cpu().numpy()\n",
        "else:\n",
        "    test_time = np.arange(len(data.test_mask))[data.test_mask.cpu().numpy()]\n",
        "\n",
        "entropy_test = entropy_mc\n",
        "\n",
        "unique_times = np.unique(test_time)\n",
        "mean_entropy_per_time = []\n",
        "\n",
        "for t in unique_times:\n",
        "    mask = test_time == t\n",
        "    if mask.sum() > 0:\n",
        "    mean_ent = entropy_test[mask].mean()\n",
        "    mean_entropy_per_time.append((t, mean_ent))\n",
        "\n",
        "times, entropies = zip(*mean_entropy_per_time)\n",
        "times = list(times)\n",
        "entropies = list(entropies)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(times, entropies, '-o', linewidth=2, markersize=4)\n",
        "plt.xlabel('Time Step')\n",
        "plt.ylabel('Mean Entropy (Uncertainty)')\n",
        "plt.title('Temporal Evolution of Model Uncertainty')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_path, 'graphge/results/figures/temporal_uncertainty.png'), dpi=200)\n",
        "plt.close()\n",
        "print(f\"Saved: {os.path.join(base_path, 'graphge/results/figures/temporal_uncertainty.png')}\")\n",
        "\n",
        "from scipy.stats import linregress\n",
        "slope, intercept, r_value, p_value, std_err = linregress(times, entropies)\n",
        "print(f\"Temporal trend: slope={slope:.6f}, r2={r_value**2:.4f}, p={p_value:.4f}\")\n",
        "\n",
        "# Save to metrics\n",
        "df = pd.read_csv(metrics_file)\n",
        "df['temporal_slope'] = slope\n",
        "df['temporal_r_squared'] = r_value**2\n",
        "df['temporal_p_value'] = p_value\n",
        "df.to_csv(metrics_file, index=False)\n",
        "print(f\"Logged to {metrics_file}\")\n",
        "\n",
        "print(\"Temporal uncertainty analysis completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcokJVshqo0B"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Alternative losses\n",
        "# -------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for handling class imbalance in fraud detection.\"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "            super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "    # Get softmax probabilities\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Get the probability of the true class\n",
        "    class_probs = probs.gather(1, labels.view(-1, 1)).squeeze(1)\n",
        "\n",
        "    # Compute focal weight: (1 - p_t)^gamma\n",
        "    focal_weight = (1 - class_probs) ** self.gamma\n",
        "\n",
        "    # Compute cross entropy\n",
        "    ce_loss = torch.nn.functional.cross_entropy(logits, labels, reduction='none')\n",
        "\n",
        "    # Apply focal weighting and alpha balancing\n",
        "    focal_loss = self.alpha * focal_weight * ce_loss\n",
        "\n",
        "    return focal_loss.mean()\n",
        "\n",
        "print(\"FocalLoss defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zNibkFPq1se"
      },
      "outputs": [],
      "source": [
        "# TRAIN WITH FOCAL LOSS + MC DROPOUT\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Reset model & optimizer\n",
        "model_focal = GraphSAGE(data.x.shape[1], 64, 2, 0.5).to(device)\n",
        "opt_focal = torch.optim.Adam(model_focal.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "loss_fn_focal = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "\n",
        "print(\"\\nTraining with Focal Loss (gamma=2.0)...\")\n",
        "for epoch in range(50):\n",
        "    model_focal.train()\n",
        "    opt_focal.zero_grad()\n",
        "    out_focal = model_focal(data.x, data.edge_index)\n",
        "    loss_focal = loss_fn_focal(out_focal[data.train_mask], data.y[data.train_mask])\n",
        "    loss_focal.backward()\n",
        "    opt_focal.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "    print(f\"Epoch {epoch+1}: Loss = {loss_focal.item():.4f}\")\n",
        "\n",
        "# MC Dropout evaluation\n",
        "probs_focal_mc, entropy_focal_mc = mc_dropout_predict(model_focal, data, data.test_mask, T=30)\n",
        "y_pred_focal = probs_focal_mc.argmax(axis=1)\n",
        "f1_focal = f1_score(y_test, y_pred_focal, zero_division=0)\n",
        "prauc_focal = average_precision_score(y_test, probs_focal_mc[:, 1])\n",
        "\n",
        "print(f\"Focal Loss results: F1={f1_focal:.4f}, PR-AUC={prauc_focal:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWAtUkMLrbzA"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model_focal.eval()\n",
        "with torch.no_grad():\n",
        "    logits_all = model_focal(data.x, data.edge_index)\n",
        "    probs_all = torch.softmax(logits_all, dim=1).cpu().numpy()\n",
        "\n",
        "probs_cs = probs_all.copy()\n",
        "alpha_smooth = 0.5\n",
        "for iteration in range(5):\n",
        "    probs_new = probs_all.copy()\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "\n",
        "    for src, tgt in edge_index.T[:1000]:\n",
        "    neighbor_prob = probs_cs[src]\n",
        "    probs_new[tgt] = alpha_smooth * neighbor_prob + (1 - alpha_smooth) * probs_all[tgt]\n",
        "\n",
        "    probs_cs = probs_new\n",
        "\n",
        "y_pred_cs = probs_cs[data.test_mask].argmax(axis=1)\n",
        "f1_cs = f1_score(y_test, y_pred_cs, zero_division=0)\n",
        "prauc_cs = average_precision_score(y_test, probs_cs[data.test_mask][:, 1])\n",
        "\n",
        "print(f\"C&S results: F1={f1_cs:.4f}, PR-AUC={prauc_cs:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDrRmwHyrmDz"
      },
      "outputs": [],
      "source": [
        "# ENSEMBLE: COMBINE BASELINE + FOCAL + C&S FOR FINAL PREDICTIONS\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get predictions from baseline model (already trained earlier)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits_base = model(data.x, data.edge_index)\n",
        "    probs_base = torch.softmax(logits_base, dim=1).cpu().numpy()\n",
        "\n",
        "# Get test set predictions from all 3 models\n",
        "probs_base_test = probs_base[data.test_mask]\n",
        "probs_focal_test = probs_focal_mc  # Already test set\n",
        "probs_cs_test = probs_cs[data.test_mask]\n",
        "\n",
        "# Simple average ensemble\n",
        "probs_ensemble = (probs_base_test + probs_focal_test + probs_cs_test) / 3.0\n",
        "y_pred_ensemble = probs_ensemble.argmax(axis=1)\n",
        "f1_ensemble = f1_score(y_test, y_pred_ensemble, zero_division=0)\n",
        "prauc_ensemble = average_precision_score(y_test, probs_ensemble[:, 1])\n",
        "\n",
        "print(f\"Ensemble results: F1={f1_ensemble:.4f}, PR-AUC={prauc_ensemble:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUCnNpZcr2f-"
      },
      "outputs": [],
      "source": [
        "# ENSEMBLE (CORRECTED): Using test-set predictions only\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Running block\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get test set predictions from all 3 models\n",
        "probs_base_test = probs_base[data.test_mask]\n",
        "probs_focal_test = probs_focal_mc  # Already test set\n",
        "probs_cs_test = probs_cs[data.test_mask]\n",
        "\n",
        "# Simple average ensemble\n",
        "probs_ensemble_test = (probs_base_test + probs_focal_test + probs_cs_test) / 3.0\n",
        "y_pred_ensemble = probs_ensemble_test.argmax(axis=1)\n",
        "f1_ensemble = f1_score(y_test, y_pred_ensemble, zero_division=0)\n",
        "prauc_ensemble = average_precision_score(y_test, probs_ensemble_test[:, 1])\n",
        "\n",
        "print(f\"Ensemble results: F1={f1_ensemble:.4f}, PR-AUC={prauc_ensemble:.4f}\")\n",
        "\n",
        "f1_final = max(f1_cs, f1_ensemble)\n",
        "prauc_final = prauc_cs if f1_cs >= f1_ensemble else prauc_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oulql7zsDGR"
      },
      "outputs": [],
      "source": [
        "# FINAL: SAVE BEST RESULTS AND GENERATE SUMMARY\n",
        "\n",
        "# Save a metrics summary table\n",
        "metrics_summary = pd.DataFrame([{\n",
        "    'method': 'Baseline_NLL',\n",
        "    'f1_score': f1,\n",
        "    'pr_auc': prauc,\n",
        "    'improvement_vs_baseline': 0.0\n",
        "}, {\n",
        "    'method': 'Focal_Loss',\n",
        "    'f1_score': f1_focal,\n",
        "    'pr_auc': prauc_focal,\n",
        "    'improvement_vs_baseline': (f1_focal-f1)*100\n",
        "}, {\n",
        "    'method': 'C&S',\n",
        "    'f1_score': f1_cs,\n",
        "    'pr_auc': prauc_cs,\n",
        "    'improvement_vs_baseline': (f1_cs-f1)*100\n",
        "}, {\n",
        "    'method': 'Ensemble_3Models',\n",
        "    'f1_score': f1_ensemble,\n",
        "    'pr_auc': prauc_ensemble,\n",
        "    'improvement_vs_baseline': (f1_ensemble-f1)*100\n",
        "}])\n",
        "\n",
        "metrics_path = os.path.join(base_path, 'graphge/results/metrics_summary.csv')\n",
        "# Writes summarized metrics to disk\n",
        "metrics_summary.to_csv(metrics_path, index=False)\n",
        "\n",
        "print(f\"Metrics summary saved to: {metrics_path}\")\n",
        "\n",
        "f1_best = max(f1_cs, f1_ensemble)\n",
        "prauc_best = prauc_cs if f1_cs >= f1_ensemble else prauc_ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNYaaNJozskC"
      },
      "outputs": [],
      "source": [
        "print('\\n' + '='*60)\n",
        "print('Running block')\n",
        "print('='*60)\n",
        "\n",
        "from torch_geometric.utils import degree as compute_degree\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "row, col = data.edge_index\n",
        "deg = compute_degree(row, num_nodes=data.num_nodes).float()\n",
        "\n",
        "test_mask_np = data.test_mask.cpu().numpy()\n",
        "test_deg = deg[test_mask_np].cpu().numpy()\n",
        "\n",
        "if len(entropy_mc) == data.num_nodes:\n",
        "    print('Detected full-graph entropy. Slicing to test nodes.')\n",
        "    test_ent = entropy_mc[test_mask_np]\n",
        "else:\n",
        "    print('Detected test-only entropy. Verifying alignment.')\n",
        "    test_ent = entropy_mc\n",
        "    assert len(test_ent) == len(test_deg), f'Shape mismatch: entropy={len(test_ent)}, degree={len(test_deg)}'\n",
        "\n",
        "bins = [0, 1, 2, 5, 10, 100, 10000]\n",
        "labels = ['1', '2', '3-5', '6-10', '11-100', '>100']\n",
        "deg_binned = pd.cut(test_deg, bins=bins, labels=labels)\n",
        "\n",
        "df_local = pd.DataFrame({\n",
        "    'degree_bin': deg_binned,\n",
        "    'epistemic_uncertainty': test_ent\n",
        "})\n",
        "\n",
        "local_stats = (\n",
        "    df_local\n",
        "    .groupby('degree_bin')['epistemic_uncertainty']\n",
        "    .agg(['mean', 'std', 'count'])\n",
        ")\n",
        "\n",
        "# Aggregates uncertainty statistics by degree bins\n",
        "print('\\nEpistemic Uncertainty by Node Degree:')\n",
        "print(local_stats)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(\n",
        "    local_stats.index.astype(str),\n",
        "    local_stats['mean'],\n",
        "    yerr=local_stats['std'],\n",
        "    capsize=5,\n",
        "    alpha=0.85,\n",
        "    edgecolor='black'\n",
        ")\n",
        "plt.title('Topological Variation of Epistemic Uncertainty')\n",
        "plt.xlabel('Node Degree (Graph Connectivity)')\n",
        "plt.ylabel('Mean Epistemic Uncertainty')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = os.path.join(base_path, 'graphge/results/figures/localized_uncertainty.png')\n",
        "plt.savefig(save_path, dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f'Saved: {save_path}')\n",
        "\n",
        "low_deg = local_stats.loc['1', 'mean']\n",
        "high_deg = local_stats.loc['>100', 'mean']\n",
        "ratio = low_deg / high_deg\n",
        "\n",
        "print(f'Degree-based uncertainty ratio: {ratio:.1f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pGzI9_X0DFe"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    if 'data' in dir():\n",
        "    # Sanity check: ensure train/test masks are disjoint\n",
        "    overlap = (data.train_mask & data.test_mask).sum().item()\n",
        "    assert overlap == 0, f'Overlap: {overlap}'\n",
        "    print('Integrity checks completed')\n",
        "    else:\n",
        "    print('Note: Running checks (data not loaded is OK)')\n",
        "except Exception as e:\n",
        "    print(f'Check status: {type(e).__name__}')\n",
        "    print('Expected if cell run independently')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}